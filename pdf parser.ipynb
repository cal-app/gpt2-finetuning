{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use this to batch convert pdfs to a single txt corpus\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir)\n",
    "for file in glob.glob(\"*.pdf\"):\n",
    "    files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir + \"/\" + files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = ''\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    path = dir + \"/\" + file\n",
    "    \n",
    "    fp = open(path, 'rb')\n",
    "    \n",
    "    parser = PDFParser(fp)\n",
    "    doc = PDFDocument()\n",
    "    parser.set_document(doc)\n",
    "    doc.set_parser(parser)\n",
    "    doc.initialize('')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    laparams = LAParams()\n",
    "    laparams.char_margin = 1.0\n",
    "    laparams.word_margin = 1.0\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "\n",
    "    for page in doc.get_pages():\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "        for lt_obj in layout:\n",
    "            if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "                extracted_text += lt_obj.get_text()\n",
    "                \n",
    "    extracted_text += '\\n\\n'\n",
    "\n",
    "with open('toshiro.txt',\"wb\") as txt_file:\n",
    "    txt_file.write(extracted_text.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"corpus.txt\"\n",
    "out_path = \"corpus_.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(in_path, encoding='utf-8') as f:\n",
    "    textclean = f.read()\n",
    "print('corpus length:', len(textclean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(textclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = {'-', ',', 'i', '?', 'I', '5', 'v', 'Q', ':', 'r', 'X', 'a', 'p', 'O', 'k', 'E', '*', '#', 'H', 'M', 'ﾟ', '^', 'g', '0', '8', 'm', 'R', 'q', ']', '\"', 'Y', 'o',  '<', 'w', '−', 'z', 'e', \"'\", '\\t', 'S', 'D', 'u', '.', 'Z', 'W', 'C', '―', 's', '/', 'U', 'G', '2', '\\n', '[', 't', '1', 'y', ')', '7', '`', '4', '3', 'A', 'T','>', ';', 'd', '(', '9', '+', 'x', '6', 'h', 'K', '%', 'N', 'n', 'L', 'B', 'F', '&', 'V', '・', 'J', '!', 'f', 'j', ' ', '~', '=', 'P', 'c', 'b', 'l'}\n",
    "charset = list(charset)\n",
    "charset.sort()\n",
    "print(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(in_path, charset, out_path):\n",
    "    with io.open(in_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    textclean = text\n",
    "    for char in textclean:\n",
    "        if char not in charset:\n",
    "            textclean = textclean.replace(char, \"\")\n",
    "        \n",
    "    f = open(out_path,\"w\", encoding=\"utf-8\") \n",
    "    f.write(textclean)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaner(in_path, charset, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
